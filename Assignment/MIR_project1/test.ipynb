{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_freq = {}\n",
    "    \n",
    "    for word in title_words_list:\n",
    "        if word not in all_words:\n",
    "            all_words_freq[word] = 1\n",
    "        else:\n",
    "            all_words_freq[word] += 1\n",
    "    \n",
    "    for word in text_words_list:\n",
    "        if word not in all_words:\n",
    "            all_words_freq[word] = 1\n",
    "        else:\n",
    "            all_words_freq[word] += 1\n",
    "    \n",
    "    normal = 0\n",
    "    for word in all_words_freq:\n",
    "        frequency = all_words_freq[word]\n",
    "        weight = 1 + math.log(frequency)\n",
    "        normal += weight * weight\n",
    "    \n",
    "    normalization[doc_id] = normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def get_stopwords(directory):\n",
    "    stopwords = []\n",
    "    for filename in os.listdir(directory):\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            for stopword in f.read().splitlines():\n",
    "                if stopword not in stopwords:\n",
    "                    stopwords.append(stopword)\n",
    "    return stopwords        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def prepare_text(raw_text):\n",
    "    prepared_text = []\n",
    "    normalizer = Normalizer()\n",
    "    normalized_text = normalizer.normalize(raw_text)\n",
    "    tokenized_text = word_tokenize(normalized_text)\n",
    "    stopwords = get_stopwords('stopwords')\n",
    "    stemmer = Stemmer()\n",
    "    \n",
    "    for token in tokenized_text:\n",
    "        if token not in stopwords:\n",
    "            stemmed_text = stemmer.stem(token)\n",
    "            if stemmed_text != \"\":\n",
    "                \n",
    "                prepared_text.append(stemmed_text.strip())\n",
    "\n",
    "    return prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def prepare_text(raw_text):\n",
    "    prepared_text = []\n",
    "    stopwords = get_stopwords('stopwords')\n",
    "    \n",
    "    normalizer = Normalizer()\n",
    "    normalized_text = normalizer.normalize(raw_text)\n",
    "    for stop in stopwords:\n",
    "        normalized_text = normalized_text.replace(stop, \" \")\n",
    "    tokenized_text = word_tokenize(normalized_text)\n",
    "    stemmer = Stemmer()\n",
    "    \n",
    "    for token in tokenized_text:\n",
    "        if token not in stopwords:\n",
    "            stemmed_text = stemmer.stem(token)\n",
    "            if stemmed_text != \"\":\n",
    "                prepared_text.append(stemmed_text)\n",
    "\n",
    "    return prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "from xml.dom.minidom import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def get_title(raw_title):\n",
    "    title = raw_title[0].childNodes[0].data\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def get_text(raw_text):\n",
    "    text = raw_text[0].childNodes[0].data\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def get_id(raw_id):\n",
    "    doc_id = raw_id[0].childNodes[0].data\n",
    "    return doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "positional_index = {}\n",
    "doc_length = {} #number of words for each documents\n",
    "\n",
    "def document_length(title_words_list, text_words_list, doc_id):\n",
    "    all_words = []\n",
    "    for word in title_words_list:\n",
    "        if word not in all_words:\n",
    "            all_words.append(word)\n",
    "    \n",
    "    for word in text_words_list:\n",
    "        if word not in all_words:\n",
    "            all_words.append(word)\n",
    "    doc_length[doc_id] = len(all_words)\n",
    "    \n",
    "\n",
    "def construct_positional_indexes(docs_path):\n",
    "    dom = parse(docs_path)\n",
    "    pages = dom.getElementsByTagName('page')    \n",
    "    for page in pages:\n",
    "        title = get_title(page.getElementsByTagName('title'))\n",
    "        text = get_text(page.getElementsByTagName('text'))\n",
    "        doc_id = get_id(page.getElementsByTagName('id'))\n",
    "        \n",
    "        text_words_list = prepare_text(text)\n",
    "        title_words_list = prepare_text(title)\n",
    "        \n",
    "        document_length(title_words_list, text_words_list, doc_id)\n",
    "        \n",
    "        for index, text_word in enumerate(text_words_list):\n",
    "            if text_word not in positional_index:\n",
    "                initializer = {doc_id: {'text': []}}\n",
    "                positional_index[text_word] = initializer\n",
    "            elif doc_id not in positional_index[text_word]:\n",
    "                positional_index[text_word][doc_id] = {'text': []}\n",
    "            elif 'text' not in positional_index[text_word][doc_id]:\n",
    "                positional_index[text_word][doc_id]['text'] = []\n",
    "            positional_index[text_word][doc_id]['text'].append(index)\n",
    "\n",
    "            \n",
    "        for index, title_word in enumerate(title_words_list):\n",
    "            if title_word not in positional_index:\n",
    "                initializer = {doc_id: {'title': []}}\n",
    "                positional_index[title_word] = initializer\n",
    "            elif doc_id not in positional_index[title_word]:\n",
    "                positional_index[title_word][doc_id] = {'title': []}\n",
    "            elif 'title' not in positional_index[title_word][doc_id]:\n",
    "                positional_index[title_word][doc_id]['title'] = []\n",
    "            positional_index[title_word][doc_id]['title'].append(index)\n",
    "    \n",
    "\n",
    "construct_positional_indexes('project1_data/data/Persian.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def get_posting_list(word):\n",
    "    # Make sure how to get posting list! From reading file or as an argument\n",
    "    return positional_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_with_bigram(bigram):\n",
    "    # WARNING: not based on slides     \n",
    "    words = []\n",
    "    for word in positional_index:\n",
    "        if bigram in word:\n",
    "            words.append(word)\n",
    "    return words\n",
    "# get_words_with_bigram('لا')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_with_bigram(bigram):\n",
    "    # WARNING: based on slides    \n",
    "    inverted_index = {}\n",
    "    for word in positional_index:\n",
    "        word_length = len(word)\n",
    "        if word_length >= 2:\n",
    "            for i in range(len(word) - 2):\n",
    "                bi = word[i: i + 2]\n",
    "                if bi not in inverted_index:\n",
    "                    inverted_index[bi] = []\n",
    "                if word not in inverted_index[bi]:\n",
    "                    inverted_index[bi].append(word)\n",
    "    return inverted_index[bigram]\n",
    "                    \n",
    "# get_words_with_bigram('لا')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_document_to_indexes(docs_path, doc_num):\n",
    "    address = docs_path + '/' + doc_num + '.xml'\n",
    "    construct_positional_indexes(address)\n",
    "\n",
    "# add_document_to_indexes('data/wiki', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_document_from_indexes(docs_path, doc_num):\n",
    "    address = docs_path + '/' + doc_num + '.xml'\n",
    "    dom = parse(address)\n",
    "    pages = dom.getElementsByTagName('page')    \n",
    "    for page in pages:\n",
    "        title = get_title(page.getElementsByTagName('title'))\n",
    "        text = get_text(page.getElementsByTagName('text'))\n",
    "        doc_id = get_id(page.getElementsByTagName('id'))\n",
    "        \n",
    "        text_words_list = prepare_text(text)\n",
    "        title_words_list = prepare_text(title)\n",
    "        \n",
    "        for index, text_word in enumerate(text_words_list):\n",
    "            if text_word not in positional_index:\n",
    "                print('کلمه پیدا نشد')\n",
    "            elif doc_id not in positional_index[text_word]:\n",
    "                print('چنین کلمه‌ای با این شماره سند موجود نیست')\n",
    "            else:\n",
    "                positional_index[text_word].remove(doc_id)\n",
    "            if len(positional_index[text_word]) == 0:\n",
    "                del positional_index[text_word]\n",
    "                \n",
    "        for index, title_word in enumerate(title_words_list):\n",
    "            if title_word not in positional_index:\n",
    "                print('کلمه پیدا نشد')\n",
    "            elif doc_id not in positional_index[title_word]:\n",
    "                print('چنین کلمه‌ای با این شماره سند موجود نیست')\n",
    "            else:\n",
    "                positional_index[title_word].remove(doc_id)\n",
    "            if len(positional_index[title_word]) == 0:\n",
    "                del positional_index[title_word]\n",
    "\n",
    "# delete_document_from_indexes('data/wiki', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index(destination):\n",
    "    full_destination = destination + '.json'\n",
    "    with open(full_destination, 'w') as f:\n",
    "        json.dump(positional_index, f, ensure_ascii=False)\n",
    "\n",
    "# save_index('storage/index_backup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done\n",
    "def positional_intersect(phrase):\n",
    "    phrases = prepare_text(phrase)\n",
    "    if len(phrases) == 1:\n",
    "        return get_posting_list(phrases[0])\n",
    "    \n",
    "    phrase_touples = []\n",
    "    \n",
    "    for i in range(len(phrases) - 1):\n",
    "        phrase_touples.append((phrases[i], phrases[i + 1]))\n",
    "    \n",
    "    answer = {}\n",
    "    \n",
    "    for index, (phrase1, phrase2) in enumerate(phrase_touples):\n",
    "        doc_list1 = {}\n",
    "        if index == 0:\n",
    "            doc_list1 = positional_index[phrase1]\n",
    "            \n",
    "        elif not answer:\n",
    "            return answer\n",
    "        \n",
    "        else:\n",
    "            doc_list1 = answer\n",
    "            answer = {}\n",
    "\n",
    "        try:\n",
    "            doc_list_len1 = len(doc_list1)\n",
    "            doc_list2 = positional_index[phrase2]\n",
    "            doc_list_len2 = len(doc_list2)\n",
    "\n",
    "        except:\n",
    "            return answer\n",
    "        i, j = 0, 0\n",
    "        while i < doc_list_len1 and j < doc_list_len2:\n",
    "            doc1_keys = list(doc_list1.keys())\n",
    "            doc2_keys = list(doc_list2.keys())\n",
    "\n",
    "\n",
    "            doc1_key = doc1_keys[i]\n",
    "            doc2_key = doc2_keys[j]\n",
    "\n",
    "\n",
    "            if doc1_key == doc2_key:\n",
    "                doc_id = doc1_key\n",
    "                contexts = ['title', 'text']\n",
    "                for context in contexts:\n",
    "                    try:\n",
    "                        context_indices1 = doc_list1[doc1_key][context]\n",
    "                        context_indices2 = doc_list2[doc2_key][context]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    m, n = 0, 0\n",
    "                    while m < len(context_indices1) and n < len(context_indices2):\n",
    "                        first_phrase_index = context_indices1[m]\n",
    "                        second_phrase_index = context_indices2[n]\n",
    "\n",
    "                        if second_phrase_index - first_phrase_index == 1:\n",
    "                            if doc_id not in answer:\n",
    "                                answer[doc_id] = {}\n",
    "\n",
    "                            if context not in answer[doc_id]:\n",
    "                                answer[doc_id][context] = []\n",
    "\n",
    "                            answer[doc_id][context].append(second_phrase_index)\n",
    "\n",
    "                            m += 1\n",
    "                            n += 1\n",
    "                        elif first_phrase_index < second_phrase_index:\n",
    "                            m += 1\n",
    "                        else:\n",
    "                            n += 1\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "\n",
    "            elif doc1_key < doc2_key:\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "#     print(answer)\n",
    "    return answer\n",
    "\n",
    "def get_phrase_occurence(phrase): \n",
    "    #count the number of occurence of phrase in docuemnts\n",
    "    documents = positional_intersect(phrase[:])\n",
    "    document_occurence = len(list(documents.keys()))\n",
    "    return document_occurence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done\n",
    "def phrase_normalizer(double_quoted):\n",
    "    new_double_quotes = []\n",
    "    for quote in double_quoted:\n",
    "        quote_list = prepare_text(quote)\n",
    "        phrase = \"\"\n",
    "        for quotes in quote_list:\n",
    "            phrase += quotes + \" \"\n",
    "        new_double_quotes.append(phrase.strip())\n",
    "    return new_double_quotes\n",
    "\n",
    "def parsing_query(query):\n",
    "    all_quotations = re.findall('\"([^\"]*)\"', query)\n",
    "    query = query.replace('\"', \"\")\n",
    "    for quoted in all_quotations:\n",
    "        query = query.replace(quoted, \"\")\n",
    "        query = query.replace('  ', \" \")\n",
    "    normalized_phrases = phrase_normalizer(all_quotations[:])\n",
    "    not_sequential = prepare_text(query)\n",
    "    return normalized_phrases, not_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done \n",
    "N = len(doc_length)\n",
    "\n",
    "def get_quoted_posting_list(phrases):\n",
    "    first_double_quote = phrases.pop()\n",
    "    first_double_quote_info = positional_intersect(first_double_quote)\n",
    "    first_double_quote_docs = list(first_double_quote_info.keys()) #docs containing the first double quote\n",
    "    answer = first_double_quote_docs\n",
    "    \n",
    "    for double_quote in phrases:\n",
    "        double_quote_info = positional_intersect(double_quote)\n",
    "        if double_quote_info:            \n",
    "            other_double_quote_docs = list(double_quote_info.keys())\n",
    "            new_answer = []\n",
    "            for ans_doc_id in answer:\n",
    "                for doc_id_other in other_double_quote_docs:\n",
    "                    if ans_doc_id == doc_id_other:\n",
    "                        new_answer.append(ans_doc_id)\n",
    "            answer = new_answer\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "def get_dictionary(query_list):\n",
    "    dic = {}\n",
    "    for term in query_list:\n",
    "        if term not in dic:\n",
    "            dic[term] = 1\n",
    "        else:\n",
    "            dic[term] += 1\n",
    "    return dic\n",
    "\n",
    "\n",
    "def consine_score(query_list, method, weight, quoted=False, double_quoted=[], contexts=['title', 'text']):\n",
    "    if quoted: #new\n",
    "        valid_docs = get_quoted_posting_list(double_quoted[:]) #docs that have all phrases\n",
    "        \n",
    "    else:\n",
    "        valid_docs = list(doc_length.keys())\n",
    "        \n",
    "    scores = {} #score of documents\n",
    "    query_terms_occurence = get_dictionary(query_list) #terms occurence in query\n",
    "    terms = list(query_terms_occurence.keys()) #all distinct terms in query\n",
    "    doc_normalization = 0\n",
    "    \n",
    "    print('terms', terms)\n",
    "\n",
    "    for term in terms:\n",
    "        if term in positional_index or term in double_quoted:\n",
    "            if quoted:\n",
    "                docs_list = positional_intersect(term)\n",
    "            else:\n",
    "                docs_list = positional_index[term]\n",
    "\n",
    "            tf_q = query_terms_occurence[term]\n",
    "            document_occurence = len(docs_list)\n",
    "            print('term:', term, 'query occ:', query_terms_occurence[term], 'doc occ:', document_occurence)\n",
    "            \n",
    "            idf = math.log(N / document_occurence)\n",
    "            w_tq = tf_q * idf\n",
    "\n",
    "            for doc in docs_list:\n",
    "                if doc in valid_docs:\n",
    "                    tf = 0\n",
    "                    for context in contexts:\n",
    "                        if 'title' in docs_list[doc] and context == 'title':\n",
    "                            title_length = len(docs_list[doc]['title'])\n",
    "                            tf += weight * (1 + math.log(title_length))\n",
    "                        elif 'text' in docs_list[doc] and context == 'text':\n",
    "                            text_length = len(docs_list[doc]['text'])\n",
    "                            tf += 1 + math.log(text_length)    \n",
    "                        w_td = tf\n",
    "                        doc_normalization += w_td * w_td\n",
    "                        if doc in scores:\n",
    "                            scores[doc] += w_tq * w_td\n",
    "                        else:\n",
    "                            scores[doc] = w_tq * w_td\n",
    "    if method == 'ltc-lnc':\n",
    "        doc_normalization = math.sqrt(doc_normalization)\n",
    "        for doc in scores:\n",
    "            scores[doc] /= doc_normalization  \n",
    "#     scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)} #TODO: not works\n",
    "    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_scores[:15]\n",
    "\n",
    "\n",
    "def search(query, method=\"ltn-lnn\", weight=2, contexts=['title', 'text']):\n",
    "    print('query', query)\n",
    "    double_quoted, not_sequential = parsing_query(query)\n",
    "\n",
    "    all_words = [] #new\n",
    "    all_words.extend(double_quoted + not_sequential) #new\n",
    "\n",
    "    if not double_quoted:\n",
    "        return consine_score(all_words[:], method, weight, contexts=contexts[:])\n",
    "    \n",
    "    return consine_score(all_words, method, weight, True, double_quoted[:], contexts=contexts[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_search(title_query, text_query, method=\"ltn-lnn\"):\n",
    "    relevant_docs = {}\n",
    "    title_score = search(title_query, method=method, weight=2, contexts=['title'])\n",
    "    text_score = search(text_query, method=method, weight=1, contexts=['text'])\n",
    "    for doc_id, score in title_score:\n",
    "        if doc_id in relevant_docs:\n",
    "            relevant_docs[doc_id] += score\n",
    "        else:\n",
    "            relevant_docs[doc_id] = score\n",
    "    \n",
    "    for doc_id, score in text_score:\n",
    "        if doc_id in relevant_docs:\n",
    "            relevant_docs[doc_id] += score\n",
    "        else:\n",
    "            relevant_docs[doc_id] = score\n",
    "            \n",
    "    scores = sorted(relevant_docs.items(), key=lambda item: item[1], reverse=True)\n",
    "    return scores[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done\n",
    "def get_queries(query_id='all'):\n",
    "    directory = 'project1_data/data/'\n",
    "    queries = {}\n",
    "    relevances = {}\n",
    "    query_directory = directory + 'queries/'\n",
    "    relevant_directory = directory + 'relevance/'\n",
    "\n",
    "    if query_id == 'all':\n",
    "        for filename in os.listdir(query_directory):\n",
    "            with open (os.path.join(query_directory, filename), 'r') as f:\n",
    "                query = f.read()\n",
    "                queries[filename[:-4]] = query\n",
    "    \n",
    "        for filename in os.listdir(relevant_directory):\n",
    "            with open (os.path.join(relevant_directory, filename), 'r') as f:\n",
    "                relevance = f.read()\n",
    "                relevant_docs = relevance.split(', ')\n",
    "                relevances[filename[:-4]] = relevant_docs\n",
    "    else:\n",
    "        query_directory += query_id + '.txt'\n",
    "        with open (query_directory, 'r') as f:\n",
    "            query = f.read()\n",
    "            queries[query_id] = query\n",
    "        \n",
    "        relevant_directory += query_id + '.txt'\n",
    "        with open (relevant_directory, 'r') as f:\n",
    "            relevance = f.read()\n",
    "            relevant_docs = relevance.split(', ')\n",
    "            relevances[query_id] = relevant_docs\n",
    "    return queries, relevances\n",
    "\n",
    "queries, relevants = get_queries(query_id='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query طبیعت دامنه کوه ایرانی\n",
      "terms ['طبیع', 'دامنه', 'کوه', 'ایران']\n",
      "term: طبیع query occ: 1 doc occ: 253\n",
      "term: دامنه query occ: 1 doc occ: 129\n",
      "term: کوه query occ: 1 doc occ: 251\n",
      "term: ایران query occ: 1 doc occ: 292\n",
      "query مطالعه \"علوم اجتماعی\" در دانشگاه\n",
      "terms ['علو اجتماع', 'مطالعه', 'در', 'دانشگاه']\n",
      "term: علو اجتماع query occ: 1 doc occ: 20\n",
      "term: مطالعه query occ: 1 doc occ: 96\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: دانشگاه query occ: 1 doc occ: 322\n",
      "query هیتلر در جنگ جهانی اول\n",
      "terms ['هیتلر', 'در', 'جنگ', 'جهان', 'اول']\n",
      "term: هیتلر query occ: 1 doc occ: 46\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جنگ query occ: 1 doc occ: 297\n",
      "term: جهان query occ: 1 doc occ: 279\n",
      "term: اول query occ: 1 doc occ: 380\n",
      "query سیاره های بزرگ \"منظومه شمسی\"\n",
      "terms ['منظومه شمس', 'سیاره', 'بزرگ']\n",
      "term: منظومه شمس query occ: 1 doc occ: 15\n",
      "term: سیاره query occ: 1 doc occ: 25\n",
      "term: بزرگ query occ: 1 doc occ: 576\n",
      "query \n",
      "terms []\n",
      "query جنگل های بلوط ایران\n",
      "terms ['جنگل', 'بلوط', 'ایر']\n",
      "term: جنگل query occ: 1 doc occ: 124\n",
      "term: بلوط query occ: 1 doc occ: 18\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "query زندگی حیوانات وحشی\n",
      "terms ['زندگ', 'حیو', 'وحش']\n",
      "term: زندگ query occ: 1 doc occ: 360\n",
      "term: حیو query occ: 1 doc occ: 60\n",
      "term: وحش query occ: 1 doc occ: 43\n",
      "query مسابقات فوتبال المپیک\n",
      "terms ['مسابق', 'فوتبال', 'المپیک']\n",
      "term: مسابق query occ: 1 doc occ: 56\n",
      "term: فوتبال query occ: 1 doc occ: 68\n",
      "term: المپیک query occ: 1 doc occ: 48\n",
      "query کشورهای عضو اتحادیه آفریقا\n",
      "terms ['کشور', 'عضو', 'اتحادیه', 'آفریقا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: عضو query occ: 1 doc occ: 189\n",
      "term: اتحادیه query occ: 1 doc occ: 117\n",
      "term: آفریقا query occ: 1 doc occ: 130\n",
      "query کتاب های برگزیده کودک و نوجوان\n",
      "terms ['کتاب', 'برگزیده', 'کودک', 'و', 'نوجو']\n",
      "term: کتاب query occ: 1 doc occ: 428\n",
      "term: برگزیده query occ: 1 doc occ: 74\n",
      "term: کودک query occ: 1 doc occ: 114\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: نوجو query occ: 1 doc occ: 17\n",
      "query برنده جایزه بهترین فیلم در جشنواره\n",
      "terms ['برنده', 'جایزه', 'به', 'فیل', 'در', 'جشنواره']\n",
      "term: برنده query occ: 1 doc occ: 56\n",
      "term: جایزه query occ: 1 doc occ: 93\n",
      "term: به query occ: 1 doc occ: 1150\n",
      "term: فیل query occ: 1 doc occ: 122\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جشنواره query occ: 1 doc occ: 47\n",
      "query ابزار های فضایی و پیشرفته ناسا\n",
      "terms ['ابزار', 'فضا', 'و', 'پیشرفته', 'ناسا']\n",
      "term: ابزار query occ: 1 doc occ: 98\n",
      "term: فضا query occ: 1 doc occ: 150\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: پیشرفته query occ: 1 doc occ: 61\n",
      "term: ناسا query occ: 1 doc occ: 26\n",
      "query سواحل دریای سرخ\n",
      "terms ['سواحل', 'دریا', 'سرخ']\n",
      "term: سواحل query occ: 1 doc occ: 67\n",
      "term: دریا query occ: 1 doc occ: 290\n",
      "term: سرخ query occ: 1 doc occ: 95\n",
      "query پایتخت کشورهای حوزه \"خلیج فارس\"\n",
      "terms ['خلیج فارس', 'پایتخ', 'کشور', 'حوزه']\n",
      "term: خلیج فارس query occ: 1 doc occ: 58\n",
      "term: پایتخ query occ: 1 doc occ: 256\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: حوزه query occ: 1 doc occ: 131\n",
      "query کشورهای دارای نفت در خاورمینا\n",
      "terms ['کشور', 'دارا', 'نف', 'در', 'خاورمینا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: دارا query occ: 1 doc occ: 471\n",
      "term: نف query occ: 1 doc occ: 97\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "query انتخابات نمایندگان مجلس ایالتی در آمریکا\n",
      "terms ['انتخاب', 'نمایندگ', 'مجلس', 'ایالت', 'در', 'آمریکا']\n",
      "term: انتخاب query occ: 1 doc occ: 220\n",
      "term: نمایندگ query occ: 1 doc occ: 90\n",
      "term: مجلس query occ: 1 doc occ: 132\n",
      "term: ایالت query occ: 1 doc occ: 170\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: آمریکا query occ: 1 doc occ: 365\n",
      "query تاریخچه هنر نمایشی در ایران\n",
      "terms ['تاریخچه', 'هنر', 'نمایش', 'در', 'ایر']\n",
      "term: تاریخچه query occ: 1 doc occ: 203\n",
      "term: هنر query occ: 1 doc occ: 245\n",
      "term: نمایش query occ: 1 doc occ: 35\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "query \"باشگاه فوتبال\" اروپایی\n",
      "terms ['باشگاه فوتبال', 'اروپا']\n",
      "term: باشگاه فوتبال query occ: 1 doc occ: 23\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "query تاریخ علوم اجتماعی در اروپا\n",
      "terms ['تاریخ', 'علو', 'اجتماع', 'در', 'اروپا']\n",
      "term: تاریخ query occ: 1 doc occ: 708\n",
      "term: علو query occ: 1 doc occ: 192\n",
      "term: اجتماع query occ: 1 doc occ: 201\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "query جاذبه گردشگری در استان کردستان\n",
      "terms ['جاذبه', 'گردشگر', 'در', 'اس', 'کردس']\n",
      "term: جاذبه query occ: 1 doc occ: 88\n",
      "term: گردشگر query occ: 1 doc occ: 137\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اس query occ: 1 doc occ: 1153\n",
      "term: کردس query occ: 1 doc occ: 57\n",
      "query درمان بیماری افسردگی\n",
      "terms ['در', 'بیمار', 'افسردگ']\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: بیمار query occ: 1 doc occ: 77\n",
      "term: افسردگ query occ: 1 doc occ: 11\n",
      "0.6082222628947458\n"
     ]
    }
   ],
   "source": [
    "def R_Precision(query_id='all'):\n",
    "    if query_id == 'all':\n",
    "        func_queries = queries\n",
    "        func_relevants = relevants\n",
    "        keys = list(func_queries.keys())\n",
    "        query_no = len(keys)\n",
    "\n",
    "    else:\n",
    "        func_queries = queries[query_id]\n",
    "        func_relevants = relevants[query_id]\n",
    "        keys = [query_id]\n",
    "        query_no = 1\n",
    "        \n",
    "    final_result = 0\n",
    "        \n",
    "    for key in keys:\n",
    "        if '\\n' in func_queries[key]:\n",
    "            title_query, text_query = func_queries[key].split('\\n')\n",
    "            related = detailed_search(title_query, text_query)\n",
    "        else:\n",
    "            related = search(func_queries[key])\n",
    "            \n",
    "        tp_list = []\n",
    "        for doc_id, score in related:\n",
    "            if doc_id in func_relevants[key]:\n",
    "                tp_list.append(doc_id)\n",
    "                \n",
    "        tp = len(tp_list)\n",
    "           \n",
    "#         print()\n",
    "#         print('func_relevants[key]', sorted(func_relevants[key]))\n",
    "#         print('tp:', tp)\n",
    "#         print('relevance', len(func_relevants[key]))\n",
    "#         print()\n",
    "        \n",
    "        final_result +=  tp / (len(func_relevants[key]))\n",
    "        \n",
    "    return final_result / query_no\n",
    "\n",
    "print(R_Precision())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query طبیعت دامنه کوه ایرانی\n",
      "terms ['طبیع', 'دامنه', 'کوه', 'ایران']\n",
      "term: طبیع query occ: 1 doc occ: 253\n",
      "term: دامنه query occ: 1 doc occ: 129\n",
      "term: کوه query occ: 1 doc occ: 251\n",
      "term: ایران query occ: 1 doc occ: 292\n",
      "query مطالعه \"علوم اجتماعی\" در دانشگاه\n",
      "terms ['علو اجتماع', 'مطالعه', 'در', 'دانشگاه']\n",
      "term: علو اجتماع query occ: 1 doc occ: 20\n",
      "term: مطالعه query occ: 1 doc occ: 96\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: دانشگاه query occ: 1 doc occ: 322\n",
      "query هیتلر در جنگ جهانی اول\n",
      "terms ['هیتلر', 'در', 'جنگ', 'جهان', 'اول']\n",
      "term: هیتلر query occ: 1 doc occ: 46\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جنگ query occ: 1 doc occ: 297\n",
      "term: جهان query occ: 1 doc occ: 279\n",
      "term: اول query occ: 1 doc occ: 380\n",
      "query سیاره های بزرگ \"منظومه شمسی\"\n",
      "terms ['منظومه شمس', 'سیاره', 'بزرگ']\n",
      "term: منظومه شمس query occ: 1 doc occ: 15\n",
      "term: سیاره query occ: 1 doc occ: 25\n",
      "term: بزرگ query occ: 1 doc occ: 576\n",
      "query \n",
      "terms []\n",
      "query جنگل های بلوط ایران\n",
      "terms ['جنگل', 'بلوط', 'ایر']\n",
      "term: جنگل query occ: 1 doc occ: 124\n",
      "term: بلوط query occ: 1 doc occ: 18\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "query زندگی حیوانات وحشی\n",
      "terms ['زندگ', 'حیو', 'وحش']\n",
      "term: زندگ query occ: 1 doc occ: 360\n",
      "term: حیو query occ: 1 doc occ: 60\n",
      "term: وحش query occ: 1 doc occ: 43\n",
      "query مسابقات فوتبال المپیک\n",
      "terms ['مسابق', 'فوتبال', 'المپیک']\n",
      "term: مسابق query occ: 1 doc occ: 56\n",
      "term: فوتبال query occ: 1 doc occ: 68\n",
      "term: المپیک query occ: 1 doc occ: 48\n",
      "query کشورهای عضو اتحادیه آفریقا\n",
      "terms ['کشور', 'عضو', 'اتحادیه', 'آفریقا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: عضو query occ: 1 doc occ: 189\n",
      "term: اتحادیه query occ: 1 doc occ: 117\n",
      "term: آفریقا query occ: 1 doc occ: 130\n",
      "query کتاب های برگزیده کودک و نوجوان\n",
      "terms ['کتاب', 'برگزیده', 'کودک', 'و', 'نوجو']\n",
      "term: کتاب query occ: 1 doc occ: 428\n",
      "term: برگزیده query occ: 1 doc occ: 74\n",
      "term: کودک query occ: 1 doc occ: 114\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: نوجو query occ: 1 doc occ: 17\n",
      "query برنده جایزه بهترین فیلم در جشنواره\n",
      "terms ['برنده', 'جایزه', 'به', 'فیل', 'در', 'جشنواره']\n",
      "term: برنده query occ: 1 doc occ: 56\n",
      "term: جایزه query occ: 1 doc occ: 93\n",
      "term: به query occ: 1 doc occ: 1150\n",
      "term: فیل query occ: 1 doc occ: 122\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جشنواره query occ: 1 doc occ: 47\n",
      "query ابزار های فضایی و پیشرفته ناسا\n",
      "terms ['ابزار', 'فضا', 'و', 'پیشرفته', 'ناسا']\n",
      "term: ابزار query occ: 1 doc occ: 98\n",
      "term: فضا query occ: 1 doc occ: 150\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: پیشرفته query occ: 1 doc occ: 61\n",
      "term: ناسا query occ: 1 doc occ: 26\n",
      "query سواحل دریای سرخ\n",
      "terms ['سواحل', 'دریا', 'سرخ']\n",
      "term: سواحل query occ: 1 doc occ: 67\n",
      "term: دریا query occ: 1 doc occ: 290\n",
      "term: سرخ query occ: 1 doc occ: 95\n",
      "query پایتخت کشورهای حوزه \"خلیج فارس\"\n",
      "terms ['خلیج فارس', 'پایتخ', 'کشور', 'حوزه']\n",
      "term: خلیج فارس query occ: 1 doc occ: 58\n",
      "term: پایتخ query occ: 1 doc occ: 256\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: حوزه query occ: 1 doc occ: 131\n",
      "query کشورهای دارای نفت در خاورمینا\n",
      "terms ['کشور', 'دارا', 'نف', 'در', 'خاورمینا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: دارا query occ: 1 doc occ: 471\n",
      "term: نف query occ: 1 doc occ: 97\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "query انتخابات نمایندگان مجلس ایالتی در آمریکا\n",
      "terms ['انتخاب', 'نمایندگ', 'مجلس', 'ایالت', 'در', 'آمریکا']\n",
      "term: انتخاب query occ: 1 doc occ: 220\n",
      "term: نمایندگ query occ: 1 doc occ: 90\n",
      "term: مجلس query occ: 1 doc occ: 132\n",
      "term: ایالت query occ: 1 doc occ: 170\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: آمریکا query occ: 1 doc occ: 365\n",
      "query تاریخچه هنر نمایشی در ایران\n",
      "terms ['تاریخچه', 'هنر', 'نمایش', 'در', 'ایر']\n",
      "term: تاریخچه query occ: 1 doc occ: 203\n",
      "term: هنر query occ: 1 doc occ: 245\n",
      "term: نمایش query occ: 1 doc occ: 35\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "query \"باشگاه فوتبال\" اروپایی\n",
      "terms ['باشگاه فوتبال', 'اروپا']\n",
      "term: باشگاه فوتبال query occ: 1 doc occ: 23\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "query تاریخ علوم اجتماعی در اروپا\n",
      "terms ['تاریخ', 'علو', 'اجتماع', 'در', 'اروپا']\n",
      "term: تاریخ query occ: 1 doc occ: 708\n",
      "term: علو query occ: 1 doc occ: 192\n",
      "term: اجتماع query occ: 1 doc occ: 201\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "query جاذبه گردشگری در استان کردستان\n",
      "terms ['جاذبه', 'گردشگر', 'در', 'اس', 'کردس']\n",
      "term: جاذبه query occ: 1 doc occ: 88\n",
      "term: گردشگر query occ: 1 doc occ: 137\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اس query occ: 1 doc occ: 1153\n",
      "term: کردس query occ: 1 doc occ: 57\n",
      "query درمان بیماری افسردگی\n",
      "terms ['در', 'بیمار', 'افسردگ']\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: بیمار query occ: 1 doc occ: 77\n",
      "term: افسردگ query occ: 1 doc occ: 11\n",
      "0.5565401403920328\n"
     ]
    }
   ],
   "source": [
    "def F_measure(query_id='all'):\n",
    "    if query_id == 'all':\n",
    "        func_queries = queries\n",
    "        func_relevants = relevants\n",
    "        keys = list(func_queries.keys())\n",
    "        query_no = len(queries)\n",
    "\n",
    "    else:\n",
    "        func_queries = queries[query_id]\n",
    "        func_relevants = relevants[query_id]\n",
    "        keys = [query_id]\n",
    "        query_no = 1\n",
    "    \n",
    "    result = 0\n",
    "    \n",
    "    for key in keys:\n",
    "        if '\\n' in func_queries[key]:\n",
    "            title_query, text_query = func_queries[key].split('\\n')\n",
    "            related = detailed_search(title_query, text_query)\n",
    "        else:\n",
    "            related = search(func_queries[key])\n",
    "        \n",
    "        tp_list = []\n",
    "        for doc_id, score in related:\n",
    "            if doc_id in func_relevants[key]:\n",
    "                tp_list.append(doc_id)\n",
    "                \n",
    "        tp = len(tp_list)\n",
    "        p = tp / len(related)\n",
    "        r = tp / len(func_relevants[key])\n",
    "        \n",
    "        if p + r != 0:\n",
    "            result = result + (2 * p * r)/(p + r)\n",
    "    \n",
    "    final_result = result / query_no\n",
    "    return final_result\n",
    "\n",
    "print(F_measure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query طبیعت دامنه کوه ایرانی\n",
      "terms ['طبیع', 'دامنه', 'کوه', 'ایران']\n",
      "term: طبیع query occ: 1 doc occ: 253\n",
      "term: دامنه query occ: 1 doc occ: 129\n",
      "term: کوه query occ: 1 doc occ: 251\n",
      "term: ایران query occ: 1 doc occ: 292\n",
      "query مطالعه \"علوم اجتماعی\" در دانشگاه\n",
      "terms ['علو اجتماع', 'مطالعه', 'در', 'دانشگاه']\n",
      "term: علو اجتماع query occ: 1 doc occ: 20\n",
      "term: مطالعه query occ: 1 doc occ: 96\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: دانشگاه query occ: 1 doc occ: 322\n",
      "query هیتلر در جنگ جهانی اول\n",
      "terms ['هیتلر', 'در', 'جنگ', 'جهان', 'اول']\n",
      "term: هیتلر query occ: 1 doc occ: 46\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جنگ query occ: 1 doc occ: 297\n",
      "term: جهان query occ: 1 doc occ: 279\n",
      "term: اول query occ: 1 doc occ: 380\n",
      "query سیاره های بزرگ \"منظومه شمسی\"\n",
      "terms ['منظومه شمس', 'سیاره', 'بزرگ']\n",
      "term: منظومه شمس query occ: 1 doc occ: 15\n",
      "term: سیاره query occ: 1 doc occ: 25\n",
      "term: بزرگ query occ: 1 doc occ: 576\n",
      "query \n",
      "terms []\n",
      "query جنگل های بلوط ایران\n",
      "terms ['جنگل', 'بلوط', 'ایر']\n",
      "term: جنگل query occ: 1 doc occ: 124\n",
      "term: بلوط query occ: 1 doc occ: 18\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "query زندگی حیوانات وحشی\n",
      "terms ['زندگ', 'حیو', 'وحش']\n",
      "term: زندگ query occ: 1 doc occ: 360\n",
      "term: حیو query occ: 1 doc occ: 60\n",
      "term: وحش query occ: 1 doc occ: 43\n",
      "query مسابقات فوتبال المپیک\n",
      "terms ['مسابق', 'فوتبال', 'المپیک']\n",
      "term: مسابق query occ: 1 doc occ: 56\n",
      "term: فوتبال query occ: 1 doc occ: 68\n",
      "term: المپیک query occ: 1 doc occ: 48\n",
      "query کشورهای عضو اتحادیه آفریقا\n",
      "terms ['کشور', 'عضو', 'اتحادیه', 'آفریقا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: عضو query occ: 1 doc occ: 189\n",
      "term: اتحادیه query occ: 1 doc occ: 117\n",
      "term: آفریقا query occ: 1 doc occ: 130\n",
      "query کتاب های برگزیده کودک و نوجوان\n",
      "terms ['کتاب', 'برگزیده', 'کودک', 'و', 'نوجو']\n",
      "term: کتاب query occ: 1 doc occ: 428\n",
      "term: برگزیده query occ: 1 doc occ: 74\n",
      "term: کودک query occ: 1 doc occ: 114\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: نوجو query occ: 1 doc occ: 17\n",
      "query برنده جایزه بهترین فیلم در جشنواره\n",
      "terms ['برنده', 'جایزه', 'به', 'فیل', 'در', 'جشنواره']\n",
      "term: برنده query occ: 1 doc occ: 56\n",
      "term: جایزه query occ: 1 doc occ: 93\n",
      "term: به query occ: 1 doc occ: 1150\n",
      "term: فیل query occ: 1 doc occ: 122\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جشنواره query occ: 1 doc occ: 47\n",
      "query ابزار های فضایی و پیشرفته ناسا\n",
      "terms ['ابزار', 'فضا', 'و', 'پیشرفته', 'ناسا']\n",
      "term: ابزار query occ: 1 doc occ: 98\n",
      "term: فضا query occ: 1 doc occ: 150\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: پیشرفته query occ: 1 doc occ: 61\n",
      "term: ناسا query occ: 1 doc occ: 26\n",
      "query سواحل دریای سرخ\n",
      "terms ['سواحل', 'دریا', 'سرخ']\n",
      "term: سواحل query occ: 1 doc occ: 67\n",
      "term: دریا query occ: 1 doc occ: 290\n",
      "term: سرخ query occ: 1 doc occ: 95\n",
      "query پایتخت کشورهای حوزه \"خلیج فارس\"\n",
      "terms ['خلیج فارس', 'پایتخ', 'کشور', 'حوزه']\n",
      "term: خلیج فارس query occ: 1 doc occ: 58\n",
      "term: پایتخ query occ: 1 doc occ: 256\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: حوزه query occ: 1 doc occ: 131\n",
      "query کشورهای دارای نفت در خاورمینا\n",
      "terms ['کشور', 'دارا', 'نف', 'در', 'خاورمینا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: دارا query occ: 1 doc occ: 471\n",
      "term: نف query occ: 1 doc occ: 97\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "query انتخابات نمایندگان مجلس ایالتی در آمریکا\n",
      "terms ['انتخاب', 'نمایندگ', 'مجلس', 'ایالت', 'در', 'آمریکا']\n",
      "term: انتخاب query occ: 1 doc occ: 220\n",
      "term: نمایندگ query occ: 1 doc occ: 90\n",
      "term: مجلس query occ: 1 doc occ: 132\n",
      "term: ایالت query occ: 1 doc occ: 170\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: آمریکا query occ: 1 doc occ: 365\n",
      "query تاریخچه هنر نمایشی در ایران\n",
      "terms ['تاریخچه', 'هنر', 'نمایش', 'در', 'ایر']\n",
      "term: تاریخچه query occ: 1 doc occ: 203\n",
      "term: هنر query occ: 1 doc occ: 245\n",
      "term: نمایش query occ: 1 doc occ: 35\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "query \"باشگاه فوتبال\" اروپایی\n",
      "terms ['باشگاه فوتبال', 'اروپا']\n",
      "term: باشگاه فوتبال query occ: 1 doc occ: 23\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "query تاریخ علوم اجتماعی در اروپا\n",
      "terms ['تاریخ', 'علو', 'اجتماع', 'در', 'اروپا']\n",
      "term: تاریخ query occ: 1 doc occ: 708\n",
      "term: علو query occ: 1 doc occ: 192\n",
      "term: اجتماع query occ: 1 doc occ: 201\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "query جاذبه گردشگری در استان کردستان\n",
      "terms ['جاذبه', 'گردشگر', 'در', 'اس', 'کردس']\n",
      "term: جاذبه query occ: 1 doc occ: 88\n",
      "term: گردشگر query occ: 1 doc occ: 137\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اس query occ: 1 doc occ: 1153\n",
      "term: کردس query occ: 1 doc occ: 57\n",
      "query درمان بیماری افسردگی\n",
      "terms ['در', 'بیمار', 'افسردگ']\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: بیمار query occ: 1 doc occ: 77\n",
      "term: افسردگ query occ: 1 doc occ: 11\n",
      "0.7373363737148075\n"
     ]
    }
   ],
   "source": [
    "def MAP(query_id='all'):\n",
    "    if query_id == 'all':\n",
    "        func_queries = queries\n",
    "        func_relevants = relevants\n",
    "        keys = list(func_queries.keys())\n",
    "    else:\n",
    "        func_queries = queries[query_id]\n",
    "        func_relevants = relevants[query_id]\n",
    "        keys = [query_id]\n",
    "    \n",
    "    ap = 0\n",
    "    \n",
    "    for key in keys:\n",
    "        if '\\n' in func_queries[key]:\n",
    "            title_query, text_query = func_queries[key].split('\\n')\n",
    "            related = detailed_search(title_query, text_query)\n",
    "        else:\n",
    "            related = search(func_queries[key])\n",
    "            \n",
    "        p_at_k_sum, tp = 0, 0\n",
    "        for i, (doc_id, score) in enumerate(related):\n",
    "            if doc_id in func_relevants[key]:\n",
    "                tp += 1\n",
    "                p_at_k_sum += tp / (i + 1)\n",
    "                \n",
    "        if tp != 0:\n",
    "            ap += p_at_k_sum / tp\n",
    "    return ap / len(keys)\n",
    "\n",
    "print(MAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query طبیعت دامنه کوه ایرانی\n",
      "terms ['طبیع', 'دامنه', 'کوه', 'ایران']\n",
      "term: طبیع query occ: 1 doc occ: 253\n",
      "term: دامنه query occ: 1 doc occ: 129\n",
      "term: کوه query occ: 1 doc occ: 251\n",
      "term: ایران query occ: 1 doc occ: 292\n",
      "func_relevants[key] ['6459', '3874', '5381', '6289', '3197', '4081', '3199', '6735', '4094', '5619', '6836', '7143', '3654', '3690', '4339', '5503', '4460', '5620', '6840', '6963', '6497', '3027']\n",
      "related ('3874', 25.83848887855718)\n",
      "query مطالعه \"علوم اجتماعی\" در دانشگاه\n",
      "terms ['علو اجتماع', 'مطالعه', 'در', 'دانشگاه']\n",
      "term: علو اجتماع query occ: 1 doc occ: 20\n",
      "term: مطالعه query occ: 1 doc occ: 96\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: دانشگاه query occ: 1 doc occ: 322\n",
      "func_relevants[key] ['6694', '6791', '6973', '5428', '5872', '4388', '6506', '6907', '6634', '5571']\n",
      "related ('6791', 27.50550315987535)\n",
      "query هیتلر در جنگ جهانی اول\n",
      "terms ['هیتلر', 'در', 'جنگ', 'جهان', 'اول']\n",
      "term: هیتلر query occ: 1 doc occ: 46\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جنگ query occ: 1 doc occ: 297\n",
      "term: جهان query occ: 1 doc occ: 279\n",
      "term: اول query occ: 1 doc occ: 380\n",
      "func_relevants[key] ['4671', '3894', '3901', '4391', '4394', '4398', '4400', '4670', '4679', '4784', '6867', '6931', '7059']\n",
      "related ('3894', 60.32720269218871)\n",
      "query سیاره های بزرگ \"منظومه شمسی\"\n",
      "terms ['منظومه شمس', 'سیاره', 'بزرگ']\n",
      "term: منظومه شمس query occ: 1 doc occ: 15\n",
      "term: سیاره query occ: 1 doc occ: 25\n",
      "term: بزرگ query occ: 1 doc occ: 576\n",
      "query \n",
      "terms []\n",
      "func_relevants[key] ['3414', '3416', '3903', '4255', '4259', '4376', '4573', '4624', '4627', '4659', '5724', '6266', '6629']\n",
      "related ('3415', 8.282456296241902)\n",
      "query جنگل های بلوط ایران\n",
      "terms ['جنگل', 'بلوط', 'ایر']\n",
      "term: جنگل query occ: 1 doc occ: 124\n",
      "term: بلوط query occ: 1 doc occ: 18\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "func_relevants[key] ['6459', '3874', '5381', '4081', '3690', '3248', '6369', '5615', '6396', '6359']\n",
      "related ('6459', 30.580799618657966)\n",
      "query زندگی حیوانات وحشی\n",
      "terms ['زندگ', 'حیو', 'وحش']\n",
      "term: زندگ query occ: 1 doc occ: 360\n",
      "term: حیو query occ: 1 doc occ: 60\n",
      "term: وحش query occ: 1 doc occ: 43\n",
      "func_relevants[key] ['4172', '5203', '5192', '3751', '5293', '7143', '5508', '6187', '4339', '5517', '4864']\n",
      "related ('4172', 30.934387154760472)\n",
      "query مسابقات فوتبال المپیک\n",
      "terms ['مسابق', 'فوتبال', 'المپیک']\n",
      "term: مسابق query occ: 1 doc occ: 56\n",
      "term: فوتبال query occ: 1 doc occ: 68\n",
      "term: المپیک query occ: 1 doc occ: 48\n",
      "func_relevants[key] ['6753', '5509', '4718', '3103', '5381', '6915', '4094', '4530', '6870', '6840', '7055', '6798', '6850', '6417', '6667', '7134', '6978', '6871']\n",
      "related ('6417', 54.07660067190504)\n",
      "query کشورهای عضو اتحادیه آفریقا\n",
      "terms ['کشور', 'عضو', 'اتحادیه', 'آفریقا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: عضو query occ: 1 doc occ: 189\n",
      "term: اتحادیه query occ: 1 doc occ: 117\n",
      "term: آفریقا query occ: 1 doc occ: 130\n",
      "func_relevants[key] ['6836', '3654', '6870', '6963', '6957', '7144', '6849', '6850', '6667', '7104', '7153', '7134', '6838', '6966', '7132', '7099', '7141', '7098', '3842']\n",
      "related ('3120', 43.971464145053325)\n",
      "query کتاب های برگزیده کودک و نوجوان\n",
      "terms ['کتاب', 'برگزیده', 'کودک', 'و', 'نوجو']\n",
      "term: کتاب query occ: 1 doc occ: 428\n",
      "term: برگزیده query occ: 1 doc occ: 74\n",
      "term: کودک query occ: 1 doc occ: 114\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: نوجو query occ: 1 doc occ: 17\n",
      "func_relevants[key] ['3666', '3894', '4337', '4398', '4838', '5293', '5381', '5390', '6840', '7002\\n\\n\\n']\n",
      "related ('4838', 31.114477445445708)\n",
      "query برنده جایزه بهترین فیلم در جشنواره\n",
      "terms ['برنده', 'جایزه', 'به', 'فیل', 'در', 'جشنواره']\n",
      "term: برنده query occ: 1 doc occ: 56\n",
      "term: جایزه query occ: 1 doc occ: 93\n",
      "term: به query occ: 1 doc occ: 1150\n",
      "term: فیل query occ: 1 doc occ: 122\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: جشنواره query occ: 1 doc occ: 47\n",
      "func_relevants[key] ['3838', '3965', '4094', '4718', '6591', '6640', '6791', '7002', '4743', '6752', '6915']\n",
      "related ('3965', 52.68292472770769)\n",
      "query ابزار های فضایی و پیشرفته ناسا\n",
      "terms ['ابزار', 'فضا', 'و', 'پیشرفته', 'ناسا']\n",
      "term: ابزار query occ: 1 doc occ: 98\n",
      "term: فضا query occ: 1 doc occ: 150\n",
      "term: و query occ: 1 doc occ: 1186\n",
      "term: پیشرفته query occ: 1 doc occ: 61\n",
      "term: ناسا query occ: 1 doc occ: 26\n",
      "func_relevants[key] ['4376', '4573', '4718', '6634', '7013', '3415', '4259', '4624', '6731', '6771\\n']\n",
      "related ('4376', 56.19543467427913)\n",
      "query سواحل دریای سرخ\n",
      "terms ['سواحل', 'دریا', 'سرخ']\n",
      "term: سواحل query occ: 1 doc occ: 67\n",
      "term: دریا query occ: 1 doc occ: 290\n",
      "term: سرخ query occ: 1 doc occ: 95\n",
      "func_relevants[key] ['5509', '4864', '5236', '4081', '3199', '3894', '3277', '6836', '7143', '3654', '4460', '5620', '6957', '3918', '3280', '3843', '6844', '7153']\n",
      "related ('3671', 28.81536245869647)\n",
      "query پایتخت کشورهای حوزه \"خلیج فارس\"\n",
      "terms ['خلیج فارس', 'پایتخ', 'کشور', 'حوزه']\n",
      "term: خلیج فارس query occ: 1 doc occ: 58\n",
      "term: پایتخ query occ: 1 doc occ: 256\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: حوزه query occ: 1 doc occ: 131\n",
      "func_relevants[key] ['3260', '3654', '3666', '3667', '4460', '4557', '5967', '6186', '6233', '6838', '7144\\n\\n']\n",
      "related ('3666', 26.568305122696362)\n",
      "query کشورهای دارای نفت در خاورمینا\n",
      "terms ['کشور', 'دارا', 'نف', 'در', 'خاورمینا']\n",
      "term: کشور query occ: 1 doc occ: 719\n",
      "term: دارا query occ: 1 doc occ: 471\n",
      "term: نف query occ: 1 doc occ: 97\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "func_relevants[key] ['3220', '3260', '3654', '3996', '4460', '6233', '6369', '6838', '6949', '7144', '7145\\n\\n\\n']\n",
      "related ('4938', 28.66552052429657)\n",
      "query انتخابات نمایندگان مجلس ایالتی در آمریکا\n",
      "terms ['انتخاب', 'نمایندگ', 'مجلس', 'ایالت', 'در', 'آمریکا']\n",
      "term: انتخاب query occ: 1 doc occ: 220\n",
      "term: نمایندگ query occ: 1 doc occ: 90\n",
      "term: مجلس query occ: 1 doc occ: 132\n",
      "term: ایالت query occ: 1 doc occ: 170\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: آمریکا query occ: 1 doc occ: 365\n",
      "func_relevants[key] ['6694', '3103', '6735', '3277', '3120', '6772', '7143', '3654', '4671', '4460', '3260', '6973', '6870', '7102', '7055', '6963', '6849', '3030', '4391', '7059', '7100', '6667', '6889']\n",
      "related ('3103', 49.906146233680765)\n",
      "query تاریخچه هنر نمایشی در ایران\n",
      "terms ['تاریخچه', 'هنر', 'نمایش', 'در', 'ایر']\n",
      "term: تاریخچه query occ: 1 doc occ: 203\n",
      "term: هنر query occ: 1 doc occ: 245\n",
      "term: نمایش query occ: 1 doc occ: 35\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: ایر query occ: 1 doc occ: 526\n",
      "func_relevants[key] ['4094', '4624', '4743', '5381', '5509', '5619', '5967', '6446', '6867', '7101', '6959\\n\\n']\n",
      "related ('5967', 27.08547215130565)\n",
      "query \"باشگاه فوتبال\" اروپایی\n",
      "terms ['باشگاه فوتبال', 'اروپا']\n",
      "term: باشگاه فوتبال query occ: 1 doc occ: 23\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "func_relevants[key] ['6753', '7134', '6978', '7136', '4530', '6798', '6885', '5381', '6900', '4537', '5509', '6794', '4094', '6417', '3666', '5967']\n",
      "related ('6753', 48.304189400552424)\n",
      "query تاریخ علوم اجتماعی در اروپا\n",
      "terms ['تاریخ', 'علو', 'اجتماع', 'در', 'اروپا']\n",
      "term: تاریخ query occ: 1 doc occ: 708\n",
      "term: علو query occ: 1 doc occ: 192\n",
      "term: اجتماع query occ: 1 doc occ: 201\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اروپا query occ: 1 doc occ: 318\n",
      "func_relevants[key] ['5293', '5967', '3666', '3874', '6694', '5509', '3099', '4718', '4335', '5381', '5508', '6289', '4401', '6735', '3277', '4254', '3938', '4671', '3260', '5553', '6973', '5554']\n",
      "related ('3120', 25.671990883099518)\n",
      "query جاذبه گردشگری در استان کردستان\n",
      "terms ['جاذبه', 'گردشگر', 'در', 'اس', 'کردس']\n",
      "term: جاذبه query occ: 1 doc occ: 88\n",
      "term: گردشگر query occ: 1 doc occ: 137\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: اس query occ: 1 doc occ: 1153\n",
      "term: کردس query occ: 1 doc occ: 57\n",
      "func_relevants[key] ['3199', '3690', '3918', '4042', '4337', '4339', '4597', '5255', '5966', '6289']\n",
      "related ('3690', 29.631471402050536)\n",
      "query درمان بیماری افسردگی\n",
      "terms ['در', 'بیمار', 'افسردگ']\n",
      "term: در query occ: 1 doc occ: 1240\n",
      "term: بیمار query occ: 1 doc occ: 77\n",
      "term: افسردگ query occ: 1 doc occ: 11\n",
      "func_relevants[key] ['4107,4838', '5462', '6572', '6627', '6711', '4050', '6014', '6768', '6973\\n\\n\\n\\n']\n",
      "related ('6669', 23.223642032021726)\n",
      "ndcg 23.995593432436376\n",
      "1.1997796716218188\n"
     ]
    }
   ],
   "source": [
    "def NDCG(query_id='all'):\n",
    "    if query_id == 'all':\n",
    "        func_queries = queries\n",
    "        func_relevants = relevants\n",
    "        keys = list(func_queries.keys())\n",
    "        query_no = len(queries)\n",
    "    else:\n",
    "        func_queries = queries[query_id]\n",
    "        func_relevants = relevants[query_id]\n",
    "        keys = [query_id]\n",
    "        query_no= 1\n",
    "    \n",
    "    ndcg = 0\n",
    "    for key in keys:\n",
    "        if '\\n' in func_queries[key]:\n",
    "            title_query, text_query = func_queries[key].split('\\n')\n",
    "            related = detailed_search(title_query, text_query)\n",
    "        else:\n",
    "            related = search(func_queries[key])\n",
    "        main = 1\n",
    "        print('func_relevants[key]', func_relevants[key])\n",
    "        for i, doc_id in enumerate(func_relevants[key]):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            main += 1 / math.log(i + 2)\n",
    "        \n",
    "        print('related', related[0])\n",
    "        for i, doc_id in enumerate(func_relevants[key]):\n",
    "            if i == 0:\n",
    "                if doc_id in func_relevants[key]:\n",
    "                    dcg = 1\n",
    "                else:\n",
    "                    dcg = 0\n",
    "            if doc_id in func_relevants[key]:\n",
    "                dcg += 1 / math.log(i + 2)\n",
    "        ndcg += dcg / main\n",
    "    print('ndcg', ndcg)\n",
    "    return ndcg/query_no\n",
    "\n",
    "print(NDCG())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '4', '5']"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '2, 4, 5'\n",
    "a.split(', ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

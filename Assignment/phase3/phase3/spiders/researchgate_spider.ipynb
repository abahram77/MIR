{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:35:05.630402Z",
     "start_time": "2020-06-16T16:35:05.096993Z"
    }
   },
   "outputs": [],
   "source": [
    "from scrapy import spiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T11:40:18.275210Z",
     "start_time": "2020-06-16T11:40:18.242026Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "module.__init__() takes at most 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-824c6deb434f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mResearchgateSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'researchgate'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mTITLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h1.publication-details__title::text'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mAUTHORS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'li.publication-author-list__item'\u001b[0m \u001b[0;31m#return array it should be wrapped authors.css('a::text).get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: module.__init__() takes at most 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "class SemanticScholarSpider(spiders):\n",
    "    name = 'semanticscholar'\n",
    "\n",
    "    TITLE = \"//h1[@data-selenium-selector='paper-detail-title']/text()\" #DONE\n",
    "    DATE = \"//span[@data-selenium-selector='paper-year']/span/span/text()\" #DONE\n",
    "    CITATIONS = \"//div[@data-selenium-selector='citation']/div/h2/a/@href\" #DONE\n",
    "    AUTHORS = \"//span[@data-selenium-selector='paper-meta-subhead']/span/span/a/span/span/text()\" #DONE\n",
    "    MORE_AUTHORS = \"//span[@data-selenium-selector='paper-meta-subhead']/span/span/span/span[@class='more-authors-label']\" #DONE\n",
    "    ABSTRACT = \"//meta[@name='description']/@content\" #DONE\n",
    "    MAXIMUM = 2000 #DONE\n",
    "    \n",
    "    \n",
    "    def __init__(self, start_urls):\n",
    "        self.start_urls = start_urls\n",
    "        self.crawled = set()\n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = self.start_urls\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "            \n",
    "    def parse(self, response):\n",
    "        url = response.url\n",
    "        data = dict()\n",
    "        id = url.split('/')[-1]\n",
    "        domain = url.split('/')[2]\n",
    "        data['id'] = id\n",
    "        data['title'] = response.xpath(self.TITLE).get()\n",
    "        data['date'] = response.xpath(self.DATE).get()\n",
    "        data['citations'] = response.xpath(self.CITATIONS).getall()\n",
    "        data['authors'] = response.xpath(self.AUTHORS).getall()\n",
    "        data['abstract'] = response.xpath(self.ABSTRACT).get()\n",
    "        \n",
    "        counter = 0\n",
    "        for citation in data['citations']:\n",
    "            if len(self.crawled) < self.MAXIMUM:\n",
    "                url_to_crawl = domain + '/' + citation\n",
    "                if counter < 10:\n",
    "                    if url_to_crawl not in self.crawled:\n",
    "                        counter += 1\n",
    "                        self.crawled.add(url_to_crawl)\n",
    "                        yield {\n",
    "                            response.follow(url_to_crawl)\n",
    "                        }\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    return\n",
    "                \n",
    "            else:\n",
    "                return\n",
    "        \n",
    "        \n",
    "START_URLS = [\n",
    "    'https://www.semanticscholar.org/paper/The-Lottery-Ticket-Hypothesis%3A-Training-Pruned-Frankle-Carbin/f90720ed12e045ac84beb94c27271d6fb8ad48cf',\n",
    "    'https://www.semanticscholar.org/paper/Attention-is-All-you-Need-Vaswani-Shazeer/204e3073870fae3d05bcbc2f6a8e263d9b72e776',\n",
    "    'https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992'   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:33:15.573391Z",
     "start_time": "2020-06-16T22:33:15.559162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1: 3}\n",
    "a[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
